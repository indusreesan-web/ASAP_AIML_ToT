[
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Workshops Attended",
    "section": "",
    "text": "2024\n\nAdvanced Tools for Literate Programming and Machine Learning, August 6-7, 2024"
  },
  {
    "objectID": "posts/post.html",
    "href": "posts/post.html",
    "title": "Another blogpost example",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Linear Regression",
    "section": "",
    "text": "Linear Regression is a type of supervised machine learning algorithm that learns from labelled datasets.\nIt maps the input data points to an optimized linear function, which can then be used to make predictions on new, unseen data.\nIt assumes that there is a linear relationship between the input and output variables.\nThis means the output changes at a constant rate as the input changes.\nThis relationship is represented using a straight line.\n\n\n\n\nConsider a scenario where we want to predict a student’s exam score based on the number of hours studied.\nAs the number of study hours increases, the exam score also increases.\nThis indicates a linear relationship.\n\n\n\nIndependent Variable (Input): Hours studied\n(This is the variable we control or observe)\nDependent Variable (Output): Exam score\n(This value depends on the hours studied)\n\nWe use the independent variable to predict the dependent variable.\n\n\n\n\n\nIn linear regression, the best-fit line is the straight line that best represents the relationship between the independent variable and the dependent variable.\nIt minimizes the difference between: - Actual observed data points\n- Predicted values produced by the model\n\n\n\n\nThe main goal of linear regression is to find a straight line that minimizes the prediction error.\nThis line helps us: - Understand the relationship between variables - Predict output values for new, unseen input data\n\n\n\n\n\nX → Independent variable (Predictor)\nY → Dependent variable (Target)\n\nLinear regression can work with: - A single feature (Simple Linear Regression) - Multiple features (Multiple Linear Regression)\n\n\n\n\nFor simple linear regression, the equation is:\ny = mx + b\nWhere: - y → Predicted output value - x → Input value - m → Slope of the line\n(How much y changes when x changes) - b → Intercept\n(Value of y when x = 0)\nThe model finds the best values of m and b so that predictions are as close as possible to actual data points.\n\n\n\n\nTo find the best-fit line, linear regression uses the Least Squares Method.\n\n\nThe difference between actual and predicted values is called a residual.\nResidual = yᵢ − ŷᵢ\nWhere: - yᵢ → Actual observed value - ŷᵢ → Predicted value for xᵢ\n\n\n\nThe least squares method minimizes the sum of squared residuals:\nSSE = Σ (yᵢ − ŷᵢ)²\nThis ensures the line fits the data as accurately as possible.\n\n\n\n\n\n\n\nIndicates how much the dependent variable changes for each unit increase in the independent variable.\nExample: If m = 5, then y increases by 5 units for every 1-unit increase in x.\n\n\n\nRepresents the predicted value of y when x = 0.\nIt is the point where the line crosses the y-axis.\n\n\n\n\nPredict a student’s exam score based on the number of hours studied.\n\nIndependent Variable (X): Hours studied\nDependent Variable (Y): Exam score\n\n\n\n\n\n```python # Linear Regression Example # Predicting exam scores based on hours studied\nimport numpy as np from sklearn.linear_model import LinearRegression import matplotlib.pyplot as plt"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Linear Regression",
    "section": "",
    "text": "Linear Regression is a type of supervised machine learning algorithm that learns from labelled datasets.\nIt maps the input data points to an optimized linear function, which can then be used to make predictions on new, unseen data.\nIt assumes that there is a linear relationship between the input and output variables.\nThis means the output changes at a constant rate as the input changes.\nThis relationship is represented using a straight line."
  },
  {
    "objectID": "index.html#example-exam-score-prediction",
    "href": "index.html#example-exam-score-prediction",
    "title": "Linear Regression",
    "section": "",
    "text": "Consider a scenario where we want to predict a student’s exam score based on the number of hours studied.\nAs the number of study hours increases, the exam score also increases.\nThis indicates a linear relationship.\n\n\n\nIndependent Variable (Input): Hours studied\n(This is the variable we control or observe)\nDependent Variable (Output): Exam score\n(This value depends on the hours studied)\n\nWe use the independent variable to predict the dependent variable."
  },
  {
    "objectID": "index.html#best-fit-line-in-linear-regression",
    "href": "index.html#best-fit-line-in-linear-regression",
    "title": "Linear Regression",
    "section": "",
    "text": "In linear regression, the best-fit line is the straight line that best represents the relationship between the independent variable and the dependent variable.\nIt minimizes the difference between: - Actual observed data points\n- Predicted values produced by the model"
  },
  {
    "objectID": "index.html#goal-of-the-best-fit-line",
    "href": "index.html#goal-of-the-best-fit-line",
    "title": "Linear Regression",
    "section": "",
    "text": "The main goal of linear regression is to find a straight line that minimizes the prediction error.\nThis line helps us: - Understand the relationship between variables - Predict output values for new, unseen input data"
  },
  {
    "objectID": "index.html#independent-and-dependent-variables",
    "href": "index.html#independent-and-dependent-variables",
    "title": "Linear Regression",
    "section": "",
    "text": "X → Independent variable (Predictor)\nY → Dependent variable (Target)\n\nLinear regression can work with: - A single feature (Simple Linear Regression) - Multiple features (Multiple Linear Regression)"
  },
  {
    "objectID": "index.html#equation-of-the-best-fit-line",
    "href": "index.html#equation-of-the-best-fit-line",
    "title": "Linear Regression",
    "section": "",
    "text": "For simple linear regression, the equation is:\ny = mx + b\nWhere: - y → Predicted output value - x → Input value - m → Slope of the line\n(How much y changes when x changes) - b → Intercept\n(Value of y when x = 0)\nThe model finds the best values of m and b so that predictions are as close as possible to actual data points."
  },
  {
    "objectID": "index.html#minimizing-error-least-squares-method",
    "href": "index.html#minimizing-error-least-squares-method",
    "title": "Linear Regression",
    "section": "",
    "text": "To find the best-fit line, linear regression uses the Least Squares Method.\n\n\nThe difference between actual and predicted values is called a residual.\nResidual = yᵢ − ŷᵢ\nWhere: - yᵢ → Actual observed value - ŷᵢ → Predicted value for xᵢ\n\n\n\nThe least squares method minimizes the sum of squared residuals:\nSSE = Σ (yᵢ − ŷᵢ)²\nThis ensures the line fits the data as accurately as possible."
  },
  {
    "objectID": "index.html#interpretation-of-the-best-fit-line",
    "href": "index.html#interpretation-of-the-best-fit-line",
    "title": "Linear Regression",
    "section": "",
    "text": "Indicates how much the dependent variable changes for each unit increase in the independent variable.\nExample: If m = 5, then y increases by 5 units for every 1-unit increase in x.\n\n\n\nRepresents the predicted value of y when x = 0.\nIt is the point where the line crosses the y-axis."
  },
  {
    "objectID": "index.html#problem-statement",
    "href": "index.html#problem-statement",
    "title": "Linear Regression",
    "section": "",
    "text": "Predict a student’s exam score based on the number of hours studied.\n\nIndependent Variable (X): Hours studied\nDependent Variable (Y): Exam score"
  },
  {
    "objectID": "index.html#linear-regression-python-code",
    "href": "index.html#linear-regression-python-code",
    "title": "Linear Regression",
    "section": "",
    "text": "```python # Linear Regression Example # Predicting exam scores based on hours studied\nimport numpy as np from sklearn.linear_model import LinearRegression import matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/another_post.html",
    "href": "posts/another_post.html",
    "title": "Blogpost Example",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
  },
  {
    "objectID": "posts/post_with_code.html",
    "href": "posts/post_with_code.html",
    "title": "A sample work",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  }
]